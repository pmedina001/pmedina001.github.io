# -*- coding: utf-8 -*-
"""Predicted Risk Heatmaps

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yvNxuOQS6Ln1V6nBvRuZbZ8ni5hdJ-t8
"""

import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import os

# Load data
df = pd.read_excel("/content/Combined_Crime_SocioEconomic_Data.xlsx")
gdf = gpd.read_file("/content/cb_2020_us_county_500k.shp")

# Filter for Florida counties only (STATEFP = '12')
gdf = gdf[gdf["STATEFP"] == "12"]
gdf = gdf[["NAME", "geometry"]].rename(columns={"NAME": "County"})

# Standardize County names
df["County"] = df["County"].str.strip().str.title()
gdf["County"] = gdf["County"].str.strip().str.title()

# Normalize crime rates per 100,000
df["Population"] = df["Population"].replace(0, 1)
crime_columns = [
    "Murder", "Rape", "Robbery", "Aggravated Assault",
    "Burglary", "Larceny", "Motor Vehicle Theft"
]
for col in crime_columns:
    df[col + " Rate"] = (df[col] / df["Population"]) * 100000

# Selected features
features = [
    "Population Density", "Housing Units", "Employment Rates",
    "Educational Attainment Levels (Bachelors Degree or Higher)", "Poverty Rates"
]

# Output directory
heatmap_dir = "/content/predicted_risk_heatmaps"
os.makedirs(heatmap_dir, exist_ok=True)

# Model selection based on previous best performers
best_models = {
    "Robbery Rate": XGBRegressor(n_estimators=50, max_depth=3, learning_rate=0.2, random_state=42),
    "Larceny Rate": RandomForestRegressor(n_estimators=100, random_state=42),
    "Motor Vehicle Theft Rate": RandomForestRegressor(n_estimators=100, random_state=42),
    "Murder Rate": RandomForestRegressor(n_estimators=100, random_state=42),
    "Rape Rate": RandomForestRegressor(n_estimators=100, random_state=42),
    "Aggravated Assault Rate": RandomForestRegressor(n_estimators=100, random_state=42),
    "Burglary Rate": RandomForestRegressor(n_estimators=100, random_state=42),
}

# Train models and generate maps
for target, model in best_models.items():
    df_model = df.dropna(subset=features + [target])
    X = df_model[features]
    y = df_model[target]
    model.fit(X, y)
    df_model[f"Predicted {target}"] = model.predict(X)

    # Merge predictions with geometry
    merged = pd.merge(gdf, df_model[["County", f"Predicted {target}"]], on="County", how="left")
    geo = gpd.GeoDataFrame(merged, geometry="geometry")

    # Plot
    fig, ax = plt.subplots(1, 1, figsize=(10, 8))
    geo.plot(column=f"Predicted {target}", cmap="Reds", linewidth=0.8,
             ax=ax, edgecolor="0.8", legend=True,
             legend_kwds={'label': f"Predicted {target} per 100k", 'shrink': 0.6})
    ax.set_title(f"{target} - Predicted Crime Risk by County (Florida)", fontsize=14)
    ax.axis("off")
    plt.tight_layout()

    # Save
    plt.savefig(f"{heatmap_dir}/{target.replace(' ', '_')}_predicted_heatmap.png", dpi=300)
    plt.close()

# Show output directory
print("Heatmaps saved to:", heatmap_dir)